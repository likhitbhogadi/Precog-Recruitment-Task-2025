# PreCog-Recruitment-Task-2025

## s/Math + AI/ Reasoning in LLMs

## How to run the files

    - In the dataset_gen folder, there is a file named, datasetgen.py, run the file using the followin command
    - Command: (in `/dataset_gen`)
        - `python3 datasetgen.py`
    - This will generate the dataset in the `/sample-data/puzzles/problems.json` file

    - In the starter-code-data-gen folder, there is a sub dir, called src
    - Run prompt1.py, prompt2.py, and prompt3.py to make LLMs solve the problems and fill in the solution files
    - The solution files are in /sample-data/solutions

    - And running main.py will show how many of the problems the LLM solved correctly,
    - Command: (in `/starter-code-data-gen`)
        - `python3 main.py`

    - I have used the starter code given in the doc to validate of the solution given by LLM
    - I am using Gemini 1.5 flash API for this

    - In the `/dataset_gen/datasetgen.py` file, I added code to generate a graph of the quesiton, a state diagram, I modelled the problem as an automata theory problem
    - In which, each string in the steps is a state and the transitions are the substitutons

    - The graph.py, graph2.py and graph_generator.py are for the same purpose, to generate a graph of a problem
    - graph2.py takes the problem in sed_puzzle_dataset.json and generates the graph of the problem
    - The part which generates graph/figure in the code is commented out, to see the graph, uncomment the code, in `/dataset_gen/datasetgen.py`, lines, 191,192,
    - (Edit: Similarly the last 2 lines in other dataset generation files)

## Further description of the code and the tasks

    - The various pictures in /dataset_gen are the graphs generated by the code, mostly via the older version of the code
    - the newer version of the code is more representative of the problems on the sed puzzle website
    - It has more reusable transitions which i saw as a pattern in the problems on the sed puzzle website
    - I went from "plain substring -> empty string" way of making transitions for the problem, to modeling it as an automata theory problem of states and transitions
    - And then included dead states, cross transtions, etc to increase difficulty of the problem
    - I saw changing heuristics like
        - Size of strings at various steps
        - Number of steps
        - Number of transitions
        - Number of states
        - Number of cross transitions
        - Number of dead states
        - The sample space of random generations and different types of random generations changed the difficulty of the problem and made it more or less representative of the problems on the sed puzzle website.
    - I came to the conclusion that the problems on the sed puzzle website can mostly be modelled as automata theory problems and the heuristics I used in the code are moderately representative of the problems on the website.
    - I was short of time to document, analyze, and show different heuristics.
    - The same is the case with prompting - Task-2.
    - I used the 3 prompting methods: zero shot, few shot, and chain of thought. Although I was not able to do them rigorously to get good results, mostly I got a score of 0.(Edit: It was because the dataset was too difficult for the LLM to solve, reducing the difficulty gave positive considerable accuracy)
    - I was short of time to improve the accuracy.
    - The 3 methods are in the 3 files in `/starter-code-data-gen/src`.
        1. `prompt1.py`
        2. `prompt2.py`
        3. `prompt3.py`

    - I could not attempt Task 3 and Task 4 on time.
    - Metrics of evaluation:
        - Accuracy of LLM in solving the problems.
        - Difficulty level of the dataset.
        - Efficiency of the heuristics used.
    - Bonus - Man vs Machine:
        - Comparison of human and LLM performance on the same dataset.

## Paper Reading Task

    - The paper reading video presentation is in the `/Paper Reading` folder.

# A little late submission ( 3 hrs late )

    - Previously i was not able to get non zero accuracy because the dataet became too hard for llms to solve in the process of making it represetative of the problems on the sed puzzle website
    - Now I changed heuristics and made 3 types of datasets
    - I was able to get non-zero accuracy on the datasets
    - Easy, medium, hard
    - In:
        - `/dataset_gen/easydatasetgen.py`,
        - `/dataset_gen/mediumdatasetgen.py`,
        - `/dataset_gen/harddatasetgen.py`
    - Commands: (`in /dataset_gen`)
        - `python3 easydatasetgen.py`
        - `python3 mediumdatasetgen.py`
        - `python3 harddatasetgen.py`

## About Heuristics in the dataset gneration:

### The difficulty I talk about is the difficulty for the LLM to solve the problem

    1. Length of random string generation (assuming the length of the initial string is comparitively bigger, eg: 3 times etc)
        - This is used in generating the target of a transition randomnly, i.e., the string to be replaced, the RHS
        - The greater the length, the easier the problem, as the chances of repetition reduce, and the problem becomes more deterministic, as in, easier to find the solution as the no. of possible next steps is recuced
    2. The Sample space of the random string generation
        - This is used in the same thing as 1.
        - The greater the sample space, the harder the problem for the same reason as 1.
    3. The no. of transitions
        - The lesser the no. of transitions, the easier the problem, as the LLM will have to think for fewer steps to solve the problem
    4. Reusing transitions to reach the answer
        - This increases the difficulty of the problem a lot and I saw this as a pattern in the problems on the sed puzzle website
        - Without this, the problem will have approximately the same no. of steps in the answer as the no. of transitions
        - With this, the problem can have a lot more steps in the answer than the no. of transitions, also it can have multiple choices at each step, making the problem harder
        - We can also control the no. of reusing transitions we wish to add
    5. Dead states
        - These will add complexity as the LLM will need to avoid these
    6. Cross transitions
        - These will add complexity as the LLM will need to think for more choices at each step
    7. Length of initial string
        - This does not affect the difficulty of the problem so much by itself, together with other heuristics it will affect the difficulty of the problem
        - For example along with 1.

## Descriptions / Heuristics used in the three datasets of varying difficulty:

#### The accuracies(approx.) are using Few shot prompting, `/starter-code-data-gen/src/prompt3.py` (Was able not able to test on 100 datapoints due to API rate limiting issues)

### 1. Easy dataset

    1. Length of random string generation: Medium, 5
    2. Sample space of random string generation: Large, 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'
    3. Number of transitions: Few, 4
    4. Reusing transitions: None
    5. Dead states: None
    6. Cross transitions: None
    7. Length of initial string: Medium, 6
    8. Accuracy(approx.): 13/17, 76.47%

### 2. Medium dataset

    1. Length of random string generation: Short, 3
    2. Sample space of random string generation: Medium, 'ABCDEFGHIJKL'
    3. Number of transitions: Moderate, 6
    4. Reusing transitions: None
    5. Dead states: None
    6. Cross transitions: None
    7. Length of initial string: Medium, 8
    8. Accuracy(approx.): 4/14, 28.57%

### 3. Hard dataset

    1. Length of random string generation: Short, 2
    2. Sample space of random string generation: Small, 'ABCDEFG'
    3. Number of transitions: Moderate, 6
    4. Reusing transitions: Few, max of 3 per transition
    5. Dead states: None
    6. Cross transitions: None
    7. Length of initial string: Meduim, 7
    8. Accuracy(approx.): 2/16, 12.5%

### 3. Hard dataset 2.0

    1. Length of random string generation: Short, 2
    2. Sample space of random string generation: Small, 'ABC'
    3. Number of transitions: Moderate, 6
    4. Reusing transitions: Medium, max of 4 per transition
    5. Dead states: None
    6. Cross transitions: None
    7. Length of initial string: Long, 10
    8. Accuracy(approx.): 0/20, 0%

## About the prompts
    - I felt that few shot prompting was the best among the three
    - I did not add Cross transitons and Dead states, as even without then the hard dataset was too hard for the LLM to solve
    - I was not able to test on 100 datapoints due to API rate limiting issues
    - I felt the hard and hard 2.0 datasets were the most representative of the problems on the sed puzzle website
